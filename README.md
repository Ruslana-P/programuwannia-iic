# Machine Era Django Project

"Machine Era" — це навчальний та демонстраційний проект, який дозволяє користувачам завантажувати зображення, відео та аудіо для аналізу за допомогою сучасних AI-моделей. Проект показує інтеграцію штучного інтелекту у веб-додатки на базі Django."

Проект побудований на стандартній архітектурі Django: використовується `manage.py`, базові налаштування у `settings.py`, URL-маршрути у `urls.py`, база даних за замовчуванням SQLite. Додаток `machine_era` містить логіку для кожного модуля та шаблони для фронтенду.

---

## Системні вимоги

- Python >= 3.10  
- Django >= 4.2  
- TensorFlow >= 2.12  
- ultralytics >= 8.0  
- Pydub >= 0.25  
- opencv-python >= 4.7  

---

## Структура проекту

## Project Structure

```text
djangotutorial/
├── manage.py
├── db.sqlite3
└── mysite/
    ├── settings.py
    ├── urls.py
    └── ...

machine_era/
├── ai_model.py        # Image classification (VGG16)
├── ai_video_model.py  # Video object detection (YOLOv8)
├── ai_audio_model.py  # Audio analysis (YAMNet)
├── views.py
├── forms.py
├── models.py
├── templates/
└── static/
```


### Головний дашборд

Головна сторінка проекту (`main_dashboard`) служить меню для модулів:  
1. **Image recognition (Module Alpha)**  
2. **Video element scan (Module Beta)**  
3. **Audio signature analysis (Module Gamma)**  
4. **Signal spectrum decode (Module Delta)** – ще не реалізовано  
5. **CUSTOM AI VARIANT (Module Epsilon)** – ще не реалізовано  

Кожен модуль має власну форму для завантаження файлів і сторінку з результатами аналізу.

### Module 1 - Image recognition
Цей модуль відповідає за завантаження зображень користувачем та їх класифікацію за допомогою штучного інтелекту.

В основі використана **VGG16**. VGG16 — це алгоритм розпізнавання та класифікації об'єктів, який може класифікувати 1000 категорій зображень з високою точністю. Модель популярна для задач класифікації зображень та легко використовується з трансферним навчанням (transfer learning).

 **Принцип роботи**
1. Зображення автоматично масштабуються до **224×224 пікселів**, щоб відповідати вимогам моделі.  
2. Зображення перетворюється у масив і проходить нормалізацію.  
3. Модель прогнозує ймовірності для всіх класів.  
4. Повертаються **топ-3 класи** з відсотком впевненості.

 **Підтримувані файли**
- **Формати:** JPEG, PNG, BMP, GIF  
- **Максимальна вага:** ~5 МБ

 **Note**
- Для коректної роботи потрібно **скачати ваги VGG16** (`vgg16_weights_tf_dim_ordering_tf_kernels.h5`) і помістити їх у папку `djangotutorial/`.  


### Module 2 - Video element scan 

Цей модуль відповідає за завантаження відео користувачем та визначення об’єктів на ключових кадрах за допомогою штучного інтелекту.

В основі використана **YOLOv8-nano**. Модель попередньо навчена на датасеті **COCO** і розпізнає **80 класів** (люди, автомобілі, тварини, предмети тощо). YOLOv8-nano оптимізована для швидкого аналізу відео з високою точністю на обмеженій кількості кадрів.  
**Файл моделі:** `yolov8n.pt` (повинен бути у проекті перед запуском).

**Принцип роботи**
1. Відео відкривається і обробляються ключові кадри (кожен 10-й кадр, до максимуму 30 кадрів).  
2. Кожен кадр аналізується моделлю YOLOv8 для виявлення об’єктів.  
3. Збираються всі виявлені класи об’єктів.  
4. Повертаються **топ-3 найпоширеніших об’єктів** та домінуючий об’єкт у відео.

**Підтримувані файли**
- **Формати:** MP4, MOV, WebM, OGG  
- **Максимальна вага:** залежить від налаштувань Django, рекомендовано ≤50 МБ  

**NOTE**
- Модель **YOLOv8-nano** автоматично завантажується при першому запуску модуля і зберігається в кеші для повторного використання.  
- Для швидкості та економії ресурсів відео аналізується лише на обмеженій кількості ключових кадрів.

### Module 3 - Audio signature analysis

Цей модуль відповідає за завантаження аудіо користувачем та розпізнавання звукових подій за допомогою штучного інтелекту.

**Модель**
В основі використана **YAMNet** від Google, завантажена через TensorFlow Hub. Модель попередньо навчена на датасеті **AudioSet** і розпізнає **521 клас звуків** (людські голоси, тварини, транспорт, інструменти та інші аудіоподії).  
Модель автоматично завантажується при першому запуску модуля і кешується для повторного використання.

**Принцип роботи**
1. Аудіофайл завантажується та приводиться до формату **моно, 16 кГц**, який вимагає YAMNet.  
2. З аудіо екстрагуються особливості (waveform).  
3. Модель прогнозує ймовірності всіх класів звуків.  
4. Визначається клас з найбільшою ймовірністю та повертається **найпоширеніша подія** з відсотком впевненості.

**Підтримувані файли**
- **Формати:** WAV, MP3, OGG та інші формати, розпізнавані бібліотекою Pydub  
- **Максимальна вага:** залежить від налаштувань Django, рекомендовано ≤20 МБ

**NOTE**
- Модель **YAMNet** автоматично завантажується з TensorFlow Hub при першому запуску і кешується для повторного використання.  

--- 
## Installation

### Prerequisites
- Python 3.9+
- pip
- virtualenv (recommended)
- ffmpeg (required for audio processing with Pydub)

---

### Setup

1. **Clone the repository**
```bash
git clone <repository-url>
cd <project-root>
```

2. Create and activate a virtual environment
```bash
python3 -m venv tutorial-env
source tutorial-env/bin/activate
```

3.Install dependencies
```bash
pip install -r requirements.txt
```
4. Apply database migrations
```bash
cd djangotutorial
python manage.py migrate
```
5. Download required AI model files 
 - Download vgg16_weights_tf_dim_ordering_tf_kernels.h5

Place the file into:
```bash
djangotutorial/
```

Run the development server
```bash
cd ./djangotutorial
python manage.py runserver
```
Open the application
```bash
http://127.0.0.1:8000/machine_era/video-results/
```